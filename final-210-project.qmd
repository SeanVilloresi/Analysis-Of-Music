---
title: "Final 210 Project"
author: "Sean Villoresi and Ellie Kang"
format: pdf
---

# Introduction

Music is an essential part of culture, creativity, and history. Specific songs and types of music can have great significance to groups of people and individuals alike. In America today, the music industry is both highly regarded and hotly debated. One successful song can launch an artist to the top of the charts, etching them into modern history. The importance of music and potential significance of a single song motivates the question - what makes a song successful?

## Data

Wanting to explore this question in our project, we found a dataset1 on Kaggle with data on Spotify streams, Youtube views, and various song characteristics. There are 28 columns, and 20,719 observations. The data was collected on Februrary 7th, 2023 by extracting the data from Youtube and Spotify. Our goal is to determine and develop the best model for predicting the success of a song based on the number of streams. We chose to use streams (as opposed to Youtube views) as our outcome variable because of inconsistencies within the data when it comes to music videos. Some music videos were not from the artist’s channel (unofficial), and we wanted to test this variable as a predictor.

Variables: We will be using streams as the model’s outcome variable. We chose the following variables as potential predictors based on their relevance to the listening experience of a song (as opposed to a more descriptive variable such as Description)
*Stream*: number of streams of the song on Spotify
*Energy*:  a measure from 0.0 to 1.0 representing a perceptual measure (dynamic range, loudness, timbre, onset rate, general entropy) of intensity and activity.
*Key*: the key the track is in measured in ntegers representing pitches using standard Pitch Class notation. E.g. 0 = C, 1 = C♯/D♭, 2 = D. If no key was detected, the value is -1.
*Loudness*: the overall loudness of a track in decibels (dB)
*Speechiness*: a measure from 0.0 to 1.0 representing the presence of spoken words in a track. 
*Acousticness*: a from 0.0 to 1.0 of whether the track is acoustic.
*Instrumentalness*: a measure from 0.0 to 1.0 that predicts whether a track contains no vocals. 
*Liveness*: a measure from 0.0 to 1.0 that detects the presence of an audience in the recording.
*Valence*: a measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track.
*Tempo*: the overall estimated tempo of a track in beats per minute (BPM).
*Duration_ms*: the duration of the track in milliseconds.
*Official_video*: boolean value that indicates if the video found is the official video of the song.

We felt that the dataset had a sufficient number of both quantitative and categorical variables to test predictability. Thus, we chose not to create additional predictors. However, in our data cleaning process, we removed any observations with missing values for streams, danceability, and licensed. After removing missing values for these variables, there were no remaining observations with missing data for relevant variables as listed above.


```{r read-data, message = F, warning = F, echo = F}
library(tidyverse)
library(tidymodels)
library(broom)
library(leaps)
library(MASS)
library(caret)
library(glmnet)
library(Stat2Data)
library(nnet)
library(lme4)
library(corrplot)
library(car)
library(reshape2)
music <- read_csv("data/Spotify_Youtube.csv")
```



```{r cleaning, message = F, warning = F, echo =F}
music$Uri=NULL
music$Url_youtube=NULL
music$Url_spotify=NULL
music$Description=NULL

music <- music[complete.cases(music$Stream), ]
music <- music[complete.cases(music$Danceability), ]
music <- music[complete.cases(music$Licensed), ]




```

## Exporatory Data Analysis

```{r distribution-streams, warning = F, echo = F, fig.width=5, fig.height=3}
ggplot(music, aes(x = Stream)) +
  geom_histogram(color = "black", fill = "lightblue", bins = 30) +
  labs(title = "Distribution of Streams",
       x = "Streams", y = "Count")
```
The distribution of the response variable Stream is skewed to the right with
most of the data having lower values for Streams. This is understandable because
a handful of songs are extremely popular while most songs on Spotify tend to be
listened to by specific niches of people.

```{r predictor-scatterplot, message = F, warning = F, echo = F, fig.width=5, fig.height=3}

ggplot(music, aes(x = Loudness, y = Stream)) +
  geom_point(color = "lightblue") +
  geom_smooth(method = "lm") +
  ggtitle("Streams vs. Loudness") +
  labs(x = "Loudness", y = "Streams")

ggplot(music, aes(x = Danceability, y = Stream)) +
  geom_point(color = "lightblue") +
  geom_smooth(method = "lm") +
  labs(title = "Streams vs. Danceability",
       x = "Danceability", y = "Streams")
```
We visualized the relationship between Streams and all the predictors in the
dataset. Danceability and Loudness showed slight positive relationships with the response variable Stream. The remaining visualizations are in the Appendix.

```{r VIF, message = F, warning = F, echo = F}
# i also cant put these in a table
model <- lm(Stream ~ Danceability + Energy + Loudness + Speechiness + 
              Acousticness + Instrumentalness + Liveness + Valence + Tempo +
            Duration_ms + official_video,
            data = music)
vif(model)
```
The results of looking at Variance Inflation Factor are values in a range between 1
and 4. Therefore, we chose to keep all the initial predictors when performing variable selection.

```{r summary-stats, message = F, warning = F, echo = F}
# i cant put these in a nice tidy table for the life of me
# also idk how to intrepret them
summary(music$Stream)
summary(music$Danceability)
summary(music$Loudness)
```

*interpretation*

# Methods

## Variable Selection

```{r setup-for-variable-selection, message = F, warning = F, echo = F}



lm_none <- lm(Stream ~ 1 , data = music)

lm_all <- lm(Stream ~ Danceability + Energy + factor(Key) + Loudness + Speechiness +
               Acousticness + Instrumentalness + Liveness +  Valence + Tempo + 
               Duration_ms + official_video, data = music)

```
To start our modeling process, we determined which variables we would use as our “baseline”, as described in our introduction above. From these, we decided the first thing we needed to do was determine if any of the variables were seen as non important/non essential, as we want to avoid overcomplicating our model. To start, we performed two variable selection methods, by using a forward and backwards stepwise method starting at our linear model for all terms, and we then proceeded to use a lasso method as well. Between these two methods, we are fairly confident that we can determine the best variables to use.

### Step-wise Selection

```{r stepwise-selection, message = F, warning = F, echo = F}
output <- capture.output(stepAIC(lm_all, 
        scope = list(lower = lm_none, upper = lm_all),
        data = music, direction = "both"))

##Just outputs final step
cat(tail(output, 39), sep = "\n")


```

### Lasso Model

```{r lasso, message = F, error = F, echo = F}
y <- music$Stream
x <- model.matrix(Stream ~ Danceability + Energy + factor(Key) + Loudness + Speechiness +
               Acousticness + Instrumentalness + Liveness +  Valence + Tempo + 
               Duration_ms + official_video,
                  data = music)

m_lasso_cv <- cv.glmnet(x, y, alpha = 1)


best_lambda <- m_lasso_cv$lambda.min
m_best <- glmnet(x, y, alpha = 1, lambda = best_lambda)
m_best$beta 

```




```{r end-of-variable-selection, message = F, error = F, echo = F}
## CHANGE LATER AFTER WE ACTUALLY CHOOSE MODELS FROM ABOVE< CURRENTLY A PLACE HOLDER.
pretransform_model <- lm(Stream ~ Danceability + Energy + factor(Key) + Loudness 
                         + Speechiness +
               Acousticness + Instrumentalness + Liveness +  Valence + Tempo + 
               Duration_ms + official_video, data = music)



```

## Linearity Assumptions and Checks for Transformations

With our variables chosen, we move on to now looking at whether our base model satisfies our assumptions required for a linear mode. We also compared our results to a transformed model where we take the log of our outcome variable Streams.

### Residual Models

```{r augment-and-residualplot, error = F, message=FALSE, echo = F, fig.width=5, fig.height=3}

ptmodel_aug <- augment(pretransform_model)

transform_model <- lm(log(Stream) ~ Danceability + Energy + factor(Key) + 
                        Loudness + Speechiness +Acousticness + Instrumentalness +                           Liveness +  Valence + Tempo + Duration_ms + 
                        official_video, data = music)

tmodel_aug <- augment(transform_model)


ggplot(ptmodel_aug, aes(x = .fitted, y=.resid)) +
  geom_point() +
  geom_hline(yintercept=0, color ="darkred") +
  labs(x ="Fitted Value of Streams", y = "Residual") +
  theme_bw()

ggplot(tmodel_aug, aes(x = .fitted, y=.resid)) +
  geom_point() +
  geom_hline(yintercept=0, color ="darkred") +
  labs(x ="Fitted Value of Streams", y = "Residual") +
  theme_bw()


```

Looking at the visualizations above, we can see that the transformed model gives us a much better spread on the residual split around our red line then our untransformed model. As such, the residuals appear roughly symmetrical along the horizontal axis for our transformed plot, so we feel it safe to assume approximate linearity, specifically for our transformed model.
 
As it relates to constant variance, we believe that our fitted values for our transformed model seem to satisfy this condition. Other than a few outliers in our negative residual side on the right, overall we seem to see fairly constant trends with how spread out our data is.



### QQ Plots

``` {r qq-plot, warning = FALSE, message = FALSE, echo = F, fig.width=5, fig.height=3}
ggplot(ptmodel_aug, aes(sample = .resid)) +
  stat_qq() + 
  stat_qq_line() + 
  theme_bw() + 
  labs(x = "Theoretical quantiles", 
       y = "Sample quantiles")

ggplot(tmodel_aug, aes(sample = .resid)) +
  stat_qq() + 
  stat_qq_line() + 
  theme_bw() + 
  labs(x = "Theoretical quantiles", 
       y = "Sample quantiles")

```

Now looking at our qq plots, we see our trend continue, where our untransformed model performs quite bad as can be seen above, while our transformed model hangs much closer to our standardized line, making it a better fit. Here, we feel safe to assume normality for our transformed plot, as other then some slight deviation towards the tails, our data points hang tight to the normal line.

# Results


# Appendix


```{r predictors}
ggplot(music, aes(x = Energy, y = Stream)) +
  geom_point(color = "blue") +
  geom_smooth(method = "lm") +
  labs(title = "Streams vs. Energy",
       x = "Energy", y = "Streams")

ggplot(music, aes(x = Key, y = Stream)) +
  geom_point(color = "blue") +
  geom_smooth(method = "lm") +
  labs(title = "Streams vs. Key",
       x = "Energy", y = "Streams")

ggplot(music, aes(x = Speechiness, y = Stream)) +
  geom_point(color = "blue") +
  geom_smooth(method = "lm") +
  labs(title = "Streams vs. Speech",
       x = "Energy", y = "Streams")

ggplot(music, aes(x = Acousticness, y = Stream)) +
  geom_point(color = "blue") +
  geom_smooth(method = "lm") +
  labs(title = "Streams vs. Acoustic",
       x = "Energy", y = "Streams")

ggplot(music, aes(x = Instrumentalness, y = Stream)) +
  geom_point(color = "blue") +
  geom_smooth(method = "lm") +
  labs(title = "Streams vs. Instrumental",
       x = "Energy", y = "Streams")

ggplot(music, aes(x = Liveness, y = Stream)) +
  geom_point(color = "blue") +
  geom_smooth(method = "lm") +
  labs(title = "Streams vs. Liveness",
       x = "Energy", y = "Streams")

ggplot(music, aes(x = Valence, y = Stream)) +
  geom_point(color = "blue") +
  geom_smooth(method = "lm") +
  labs(title = "Streams vs. Valence",
       x = "Energy", y = "Streams")

ggplot(music, aes(x = Tempo, y = Stream)) +
  geom_point(color = "blue") +
  geom_smooth(method = "lm") +
  labs(title = "Streams vs. Tempo",
       x = "Energy", y = "Streams")

ggplot(music, aes(x = Duration_ms, y = Stream)) +
  geom_point(color = "blue") +
  geom_smooth(method = "lm") +
  labs(title = "Streams vs. Duration_ms",
       x = "Energy", y = "Streams")
```


```{r}
summary(music[8:18])
```









