---
title: "Final 210 Project"
author: "Sean Villoresi and Ellie Kang"
format: pdf
editor: 
  markdown: 
    wrap: sentence
---

# Introduction

Music is an essential part of culture, creativity, and history. Specific songs and types of music can have great significance to groups of people and individuals alike. In America today, the music industry is both highly regarded and hotly debated. One successful song can launch an artist to the top of the charts, etching them into modern history. The importance of music and potential significance of a single song motivates the question - what makes a song successful?

## Data

Wanting to explore this question in our project, we found a dataset1 on Kaggle with data on Spotify streams, Youtube views, and various song characteristics. There are 28 columns, and 20,719 observations. The data was collected on Februrary 7th, 2023 by extracting the data from Youtube and Spotify. Our goal is to determine and develop the best model for predicting the success of a song based on the number of streams. We chose to use streams (as opposed to Youtube views) as our outcome variable because of inconsistencies within the data when it comes to music videos.
Some music videos were not from the artist's channel (unofficial), and we wanted to test this variable as a predictor.

Variables: We will be using streams as the model's outcome variable.
We chose the following variables as potential predictors based on their relevance to the listening experience of a song (as opposed to a more descriptive variable such as Description) *Stream*: number of streams of the song on Spotify *Energy*: a measure from 0.0 to 1.0 representing a perceptual measure (dynamic range, loudness, timbre, onset rate, general entropy) of intensity and activity. *Key*: the key the track is in measured in ntegers representing pitches using standard Pitch Class notation. E.g. 0 = C, 1 = C♯/D♭, 2 = D. If no key was detected, the value is -1. *Loudness*: the overall loudness of a track in decibels (dB) *Speechiness*: a measure from 0.0 to 1.0 representing the presence of spoken words in a track. *Acousticness*: a from 0.0 to 1.0 of whether the track is acoustic. *Instrumentalness*: a measure from 0.0 to 1.0 that predicts whether a track contains no vocals. *Liveness*: a measure from 0.0 to 1.0 that detects the presence of an audience in the recording. *Valence*: a measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. *Tempo*: the overall estimated tempo of a track in beats per minute (BPM). *Duration_ms*: the duration of the track in milliseconds. *Official_video*: boolean value that indicates if the video found is the official video of the song.

We felt that the dataset had a sufficient number of both quantitative and categorical variables to test predictability. Thus, we chose not to create additional predictors. However, in our data cleaning process, we removed any observations with missing values for streams, danceability, and licensed. After removing missing values for these variables, there were no remaining observations with missing data for relevant variables as listed above.

```{r read-data, message = F, warning = F, echo = F}
library(tidyverse)
library(tidymodels)
library(broom)
library(leaps)
library(MASS)
library(caret)
library(glmnet)
library(Stat2Data)
library(nnet)
library(lme4)
library(corrplot)
library(car)
library(reshape2)
library(gridExtra)
library(knitr)
music <- read_csv("data/Spotify_Youtube.csv")
```

```{r cleaning, message = F, warning = F, echo =F}
music$Uri=NULL
music$Url_youtube=NULL
music$Url_spotify=NULL
music$Description=NULL

music <- music[complete.cases(music$Stream), ]
music <- music[complete.cases(music$Danceability), ]
music <- music[complete.cases(music$Licensed), ]




```

## Exporatory Data Analysis

```{r distribution-streams, warning = F, echo = F, fig.width=5, fig.height=3}
ggplot(music, aes(x = Stream)) +
  geom_histogram(color = "black", fill = "lightblue", bins = 30) +
  labs(title = "Distribution of Streams",
       x = "Streams", y = "Count")
```

The distribution of the response variable Stream is skewed to the right with most of the data having lower values for Streams. This is understandable because a handful of songs are extremely popular and these outliers cause the distribution visualization to have most of the data concentrated on the left.

```{r predictor-scatterplot, message = F, warning = F, echo = F}

p1 <- ggplot(music, aes(x = Loudness, y = Stream)) +
  geom_point(color = "lightblue") +
  geom_smooth(method = "lm") +
  ggtitle("Streams vs. Loudness") +
  labs(x = "Loudness", y = "Streams")

p2 <- ggplot(music, aes(x = Danceability, y = Stream)) +
  geom_point(color = "lightblue") +
  geom_smooth(method = "lm") +
  labs(title = "Streams vs. Danceability",
       x = "Danceability", y = "Streams")

grid.arrange(p1, p2, ncol=2)
```

We visualized the relationship between Streams and all the predictors in the dataset. Danceability and Loudness showed slight positive relationships with the response variable Stream. The remaining visualizations are in the Appendix.

```{r VIF, message = F, warning = F, echo = F}
model <- lm(Stream ~ Danceability + Energy + Loudness + Speechiness + 
              Acousticness + Instrumentalness + Liveness + Valence + Tempo +
            Duration_ms + official_video,
            data = music)
kable(vif(model), caption = "VIF values")
```

The results of looking at Variance Inflation Factor are values in a range between 1 and 4. Because all the values were below 4, they did not demonstrate much multicollinearity. Thus, we chose to keep all the initial predictors when performing variable selection and did not include any interaction terms. 

```{r summary-stats, message = F, warning = F, echo = F}
summary_stats <- sapply(music[, c("Stream", "Danceability", "Loudness")], summary)


summary_df <- as.data.frame(summary_stats)

kable(summary_df, caption = "Summary Statistics of Response and Predictors of
      Interest")
```


# Methods

We will be fitting a linear model to predict streams because Stream is a non-binary numerical variable. Additionally, we are using it to represent a measure of success, and we want to determine what factors have a linear relationship with streams to determine correlations between predictors and success. Based on our EDA, we chose not to use any interaction terms.

## Variable Selection

```{r setup-for-variable-selection, message = F, warning = F, echo = F}



lm_none <- lm(Stream ~ 1 , data = music)

lm_all <- lm(Stream ~ Danceability + Energy + factor(Key) + Loudness + Speechiness +
               Acousticness + Instrumentalness + Liveness +  Valence + Tempo + 
               Duration_ms + official_video, data = music)

```

To start our modeling process, we determined which variables we would use as our "baseline", as described in our introduction above. From these, we decided the first thing we needed to do was determine if any of the variables were seen as non important/non essential, as we want to avoid overcomplicating our model. To start, we performed two variable selection methods, by using a forward and backwards stepwise method starting at our linear model for all terms, and we then proceeded to use a lasso method as well.
Between these two methods, we are fairly confident that we can determine the best variables to use.

### Step-wise Selection

```{r stepwise-selection, message = F, warning = F, echo = F}
output <- capture.output(stepAIC(lm_all, 
        scope = list(lower = lm_none, upper = lm_all),
        data = music, direction = "both"))

##Just outputs final step
#cat(tail(output, 39), sep = "\n")
```

From our stepwise method, the only variable it seemed to remove was Tempo, and even with that the change in AIC with or without tempo was fairly minimal, so it was from this point that we decided to also use lasso in order to get another perspective on the matter, knowing that stepwise functions can be very influenced by the starting model and its order of variables


### Lasso Model

```{r lasso, message = F, error = F, echo = F}
y <- music$Stream
x <- model.matrix(Stream ~ Danceability + Energy + factor(Key) + Loudness + Speechiness +
               Acousticness + Instrumentalness + Liveness +  Valence + Tempo + 
               Duration_ms + official_video,
                  data = music)

m_lasso_cv <- cv.glmnet(x, y, alpha = 1)


best_lambda <- m_lasso_cv$lambda.min
m_best <- glmnet(x, y, alpha = 1, lambda = best_lambda)

matrix_df <- as.data.frame(as.matrix(m_best$beta))
kable(matrix_df , caption = "Lasso Coefficients")

```

With lasso however, we came to the same conclusion, as our lasso kept essentially every variable to a fairly significant coefficient. As such, we have decided to move on using all of the variables that we had started with at the beginning as predictor variables


```{r end-of-variable-selection, message = F, error = F, echo = F}
## CHANGE LATER AFTER WE ACTUALLY CHOOSE MODELS FROM ABOVE< CURRENTLY A PLACE HOLDER.
pretransform_model <- lm(Stream ~ Danceability + Energy + factor(Key) + Loudness 
                         + Speechiness + Acousticness + Instrumentalness 
                         + Liveness +  Valence + Tempo + Duration_ms 
                         + official_video, 
                         data = music)



```

## Linearity Assumptions and Checks for Transformations

With our variables chosen, we move on to now looking at whether our base model satisfies our assumptions required for a linear mode. We also compared our results to a transformed model where we take the log of our outcome variable Streams.

### Residual Models

```{r augment-and-residualplot, error = F, message=FALSE, echo = F, fig.width=5, fig.height=2.5}

ptmodel_aug <- augment(pretransform_model)

transform_model <- lm(log(Stream) ~ Danceability + Energy + factor(Key) + 
                        Loudness + Speechiness +Acousticness + Instrumentalness +                           Liveness +  Valence + Tempo + Duration_ms + 
                        official_video, data = music)

tmodel_aug <- augment(transform_model)


ggplot(ptmodel_aug, aes(x = .fitted, y=.resid)) +
  geom_point() +
  geom_hline(yintercept=0, color ="darkred") +
  labs(x ="Fitted Value of Streams", y = "Residual", title = "Untransformed Model") +
  theme_bw()

ggplot(tmodel_aug, aes(x = .fitted, y=.resid)) +
  geom_point() +
  geom_hline(yintercept=0, color ="darkred") +
  labs(x ="Fitted Value of Streams", y = "Residual", title = "Transformed(Log) Model") +
  theme_bw()


```

Looking at the visualizations above, we can see that the transformed model gives us a much better spread on the residual split around our red line then our untransformed model. As such, the residuals appear roughly symmetrical along the horizontal axis for our transformed plot, so we feel it safe to assume approximate linearity, specifically for our transformed model.

As it relates to constant variance, we believe that our fitted values for our transformed model seem to satisfy this condition. Other than a few outliers in our negative residual side on the right, overall we seem to see fairly constant trends with how spread out our data is.

### QQ Plots

```{r qq-plot, warning = FALSE, message = FALSE, echo = F, fig.width=5, fig.height=2.5}
ggplot(ptmodel_aug, aes(sample = .resid)) +
  stat_qq() + 
  stat_qq_line() + 
  theme_bw() + 
  labs(x = "Theoretical quantiles", 
       y = "Sample quantiles",
       title = "Untransformed Model")

ggplot(tmodel_aug, aes(sample = .resid)) +
  stat_qq() + 
  stat_qq_line() + 
  theme_bw() + 
  labs(x = "Theoretical quantiles", 
       y = "Sample quantiles",
       title = "Transformed Model")

```

Now looking at our qq plots, we see our trend continue, where our untransformed model performs quite bad as can be seen above, while our transformed model hangs much closer to our standardized line, making it a better fit. Here, we feel safe to assume normality for our transformed plot, as other then some slight deviation towards the tails, our data points hang tight to the normal line.

For our independence assumption, we believe that our data set satisfies this condition. Our data was collected all on the same day, and the streams and/or variables associated with each song should not be impacted by those of other songs.

After looking at our two graphs above, we believe that our transformed model will provide a better measurement of our data, and provide better predicitons of a songs streams.

# Results

```{r results, message = F, echo = F, warning = F}
summary(transform_model)

```

```{r}
set.seed(1)
cv_method <- trainControl(method = "cv", number = 10)
hypothesis_model <- train(Stream ~ Danceability + Loudness,
                   data = music, method = "lm", trControl = cv_method)

all_model <- train(Stream ~ Danceability + Energy + factor(Key) + Loudness 
                         + Speechiness + Acousticness + Instrumentalness 
                   + Liveness +  Valence + Tempo + Duration_ms + official_video,
                   data = music, method = "lm", trControl = cv_method)

final_model <- train(log(Stream) ~ Danceability + Energy + factor(Key) + 
                       Loudness + Speechiness + Acousticness + Instrumentalness 
                   + Liveness +  Valence + Tempo + Duration_ms + official_video,
                   data = music, method = "lm", trControl = cv_method)

print(hypothesis_model)
print(all_model)
print(final_model)

dfmodel <- data.frame(Model = c("Hypothesis_Model", "All_Model", "Transform_Model"),
                 R_squared = c(hypothesis_model$results$Rsquared, all_model$results$Rsquared, final_model$results$Rsquared),
                 RMSE = c(hypothesis_model$results$RMSE, all_model$results$RMSE, final_model$results$RMSE))

kable(dfmodel , caption = "Model Fit Statistics")
```

# Appendix


