---
title: "Final 210 Project"
author: "Sean Villoresi and Ellie Kang"
format: pdf
---


## Read in the data

```{r read-data, message = F, warning = F}
library(tidyverse)
library(tidymodels)
library(broom)
library(leaps)
library(MASS)
library(caret)
library(glmnet)
library(Stat2Data)
library(nnet)
library(lme4)
music <- read_csv("data/Spotify_Youtube.csv")
```

##Cleaning the data

```{r cleaning, message = F, warning = F}
music$Uri=NULL
music$Url_youtube=NULL
music$Url_spotify=NULL

music <- music[complete.cases(music$Stream), ]
music <- music[complete.cases(music$Danceability), ]
music <- music[complete.cases(music$Licensed), ]
sum(is.na(music$Licensed))



```

## Variable Selection

```{r setup-for-variable-selection, message = F, warning = F}

indices <- sample(1:5000, size = 5000 * 0.8, replace = F)
train.data  <- music %>% 
  slice(indices)
test.data <- music %>% 
  slice(-indices)

lm_none <- lm(Stream ~ 1 , data = train.data)

lm_all <- lm(Stream ~ Danceability + Energy + Key + Loudness + Speechiness +
               Acousticness + Instrumentalness + Liveness +  Valence + Tempo + 
               Duration_ms + official_video, data = train.data)

```


```{r stepwise-selection, message = F, warning = F}
stepAIC(lm_all, 
        scope = list(lower = lm_none, upper = lm_all),
        data = music, direction = "both")

```

```{r lasso, message = F, error = F}
y <- music$Stream
x <- model.matrix(Stream ~ Danceability + Energy + Key + Loudness + Speechiness +
               Acousticness + Instrumentalness + Liveness +  Valence + Tempo + 
               Duration_ms + official_video,
                  data = music)

m_lasso_cv <- cv.glmnet(x, y, alpha = 1)


best_lambda <- m_lasso_cv$lambda.min
m_best <- glmnet(x, y, alpha = 1, lambda = best_lambda)
m_best$beta 

```

```{r end-of-variable-selection, message = F, error = F}
## CHANGE LATER AFTER WE ACTUALLY CHOOSE MODELS FROM ABOVE< CURRENTLY A PLACE HOLDER.
pretransform_model <- lm(Stream ~ Danceability + Energy + Key + Loudness + Speechiness +
               Acousticness + Instrumentalness + Liveness +  Valence + Tempo + 
               Duration_ms + official_video, data = music)



```

## Linearity Assumptions and Checks for Transformations

```{r augment-and-residualplot }

ptmodel_aug <- augment(pretransform_model)

transform_model <- lm(log(Stream) ~ Danceability + Energy + Key + Loudness + 
                        Speechiness +Acousticness + Instrumentalness + Liveness 
                      +  Valence + Tempo + Duration_ms + official_video, 
                      data = music)

tmodel_aug <- augment(transform_model)


ggplot(ptmodel_aug, aes(x = .fitted, y=.resid)) +
  geom_point() +
  geom_hline(yintercept=0, color ="darkred") +
  labs(x ="Fitted Value of Streams", y = "Residual") +
  theme_bw()

ggplot(tmodel_aug, aes(x = .fitted, y=.resid)) +
  geom_point() +
  geom_hline(yintercept=0, color ="darkred") +
  labs(x ="Fitted Value of Streams", y = "Residual") +
  theme_bw()


```

``` {r qq-plot, warning = FALSE, message = FALSE}
ggplot(ptmodel_aug, aes(sample = .resid)) +
  stat_qq() + 
  stat_qq_line() + 
  theme_bw() + 
  labs(x = "Theoretical quantiles", 
       y = "Sample quantiles")

```






